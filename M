import pandas as pd
import numpy as np
import statsmodels.api as sm
from sklearn.utils import resample
import matplotlib.pyplot as plt

# Assume `merged_df` contains columns 'trump_odds', 'dxy', 'spx', 'us_2y', 'us_inflation_swap_2y', and target variable

# Step 1: Create Interaction Terms
merged_df['trump_odds_dxy'] = merged_df['trump_odds'] * merged_df['dxy']
merged_df['trump_odds_spx'] = merged_df['trump_odds'] * merged_df['spx']
merged_df['trump_odds_us_2y'] = merged_df['trump_odds'] * merged_df['us_2y']
merged_df['trump_odds_inflation_swap'] = merged_df['trump_odds'] * merged_df['us_inflation_swap_2y']

# Define features and target
X = merged_df[['trump_odds', 'dxy', 'spx', 'us_2y', 'us_inflation_swap_2y', 
               'trump_odds_dxy', 'trump_odds_spx', 'trump_odds_us_2y', 'trump_odds_inflation_swap']]
X = sm.add_constant(X)  # Add intercept
y = merged_df['target']  # Replace 'target' with your actual target variable name

# Step 2: Bootstrap to Calculate Confidence Intervals
n_bootstraps = 1000
bootstrapped_coefs = []

for _ in range(n_bootstraps):
    # Resample the data with replacement
    X_resampled, y_resampled = resample(X, y)
    
    # Fit the OLS model to the bootstrap sample
    boot_model = sm.OLS(y_resampled, X_resampled).fit()
    bootstrapped_coefs.append(boot_model.params)

# Convert to DataFrame for analysis
bootstrapped_coefs_df = pd.DataFrame(bootstrapped_coefs)

# Calculate mean and confidence intervals for coefficients
coef_means = bootstrapped_coefs_df.mean()
ci_lower = bootstrapped_coefs_df.quantile(0.025)
ci_upper = bootstrapped_coefs_df.quantile(0.975)

# Step 3: Display Results in a DataFrame
results_df = pd.DataFrame({
    "Coefficient Mean": coef_means,
    "CI Lower (2.5%)": ci_lower,
    "CI Upper (97.5%)": ci_upper
})

print("Bootstrap Results with 95% Confidence Intervals for OLS with Interaction Terms:")
print(results_df)

# Step 4: Plotting the Coefficients and Confidence Intervals
plt.figure(figsize=(10, 6))
plt.errorbar(results_df.index, results_df["Coefficient Mean"], 
             yerr=[results_df["Coefficient Mean"] - results_df["CI Lower (2.5%)"], 
                   results_df["CI Upper (97.5%)"] - results_df["Coefficient Mean"]],
             fmt='o', capsize=5, color='blue', ecolor='gray', elinewidth=2, markeredgewidth=2)

plt.axhline(0, color='black', linewidth=0.8)  # Reference line at y=0
plt.title("Coefficient Estimates with 95% Confidence Intervals (Bootstrap)")
plt.xlabel("Features")
plt.ylabel("Coefficient Value")
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()









xxx



import pandas as pd
import statsmodels.api as sm
from sklearn.utils import resample

# Assume `merged_df` contains columns 'trump_odds', 'dxy', 'spx', 'us_2y', 'us_inflation_swap_2y', and target variable

# Step 1: Create Interaction Terms
merged_df['trump_odds_dxy'] = merged_df['trump_odds'] * merged_df['dxy']
merged_df['trump_odds_spx'] = merged_df['trump_odds'] * merged_df['spx']
merged_df['trump_odds_us_2y'] = merged_df['trump_odds'] * merged_df['us_2y']
merged_df['trump_odds_inflation_swap'] = merged_df['trump_odds'] * merged_df['us_inflation_swap_2y']

# Define features and target
X = merged_df[['trump_odds', 'dxy', 'spx', 'us_2y', 'us_inflation_swap_2y', 
               'trump_odds_dxy', 'trump_odds_spx', 'trump_odds_us_2y', 'trump_odds_inflation_swap']]
X = sm.add_constant(X)  # Add intercept
y = merged_df['target']  # Replace 'target' with your actual target variable name

# Step 2: Fit the Initial OLS Model to Estimate Effect Sizes
model = sm.OLS(y, X).fit()
print(model.summary())

# Step 3: Bootstrap to Calculate Confidence Intervals
n_bootstraps = 1000
bootstrapped_coefs = []

for _ in range(n_bootstraps):
    # Resample the data with replacement
    X_resampled, y_resampled = resample(X, y)
    
    # Fit the OLS model to the bootstrap sample
    boot_model = sm.OLS(y_resampled, X_resampled).fit()
    bootstrapped_coefs.append(boot_model.params)

# Convert to DataFrame for analysis
bootstrapped_coefs_df = pd.DataFrame(bootstrapped_coefs)

# Calculate mean and confidence intervals for coefficients
coef_means = bootstrapped_coefs_df.mean()
ci_lower = bootstrapped_coefs_df.quantile(0.025)
ci_upper = bootstrapped_coefs_df.quantile(0.975)

# Step 4: Display Results
results_df = pd.DataFrame({
    "Coefficient Mean": coef_means,
    "CI Lower (2.5%)": ci_lower,
    "CI Upper (97.5%)": ci_upper
})

print("Bootstrap Results with 95% Confidence Intervals for OLS with Interaction Terms:")
print(results_df)






xxx





import pandas as pd
import statsmodels.api as sm
from statsmodels.tsa.api import VAR

# Assume data is in a DataFrame `df` with columns: 'trump_odds', 'dxy', 'spx', 'us_2y', 'us_inflation_swap_2y'

# Step 1: Prepare Data
# Ensure data is stationary by differencing, if necessary
# For simplicity, this example assumes the data is already stationary. 
# Otherwise, you might need to apply differencing: df['dxy'] = df['dxy'].diff().dropna() (do this for each column if needed)

# Selecting the variables for the VAR model
df_var = df[['trump_odds', 'dxy', 'spx', 'us_2y', 'us_inflation_swap_2y']]

# Step 2: Fit the VAR Model
model = VAR(df_var)
lag_order = model.select_order()  # Select the optimal lag order based on AIC or BIC
print("Selected Lag Order:", lag_order.selected_orders)

# Fitting the model with the selected lag order
var_model = model.fit(lag_order.aic)
print(var_model.summary())

# Step 3: Impulse Response Function (IRF)
# We will analyze how a shock in 'trump_odds' affects each variable in the system
irf = var_model.irf(10)  # Calculate IRF over a 10-day horizon; adjust as needed
irf.plot(orth=False)  # Plot the IRF, orthogonalization is False to show direct impact






xxx


import pandas as pd
import numpy as np
from sklearn.model_selection import cross_val_score
from sklearn.linear_model import Ridge
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import make_pipeline

# Assume data is in a DataFrame `df` with columns: 'trump_odds', 'dxy', 'spx', 'us_2y', 'us_inflation_swap_2y'

# Step 1: Prepare Data
# Adding interaction terms manually
df['trump_odds_dxy'] = df['trump_odds'] * df['dxy']
df['trump_odds_spx'] = df['trump_odds'] * df['spx']
df['trump_odds_us_2y'] = df['trump_odds'] * df['us_2y']
df['trump_odds_inflation_swap'] = df['trump_odds'] * df['us_inflation_swap_2y']

# Define features and target
X = df[['trump_odds', 'dxy', 'spx', 'us_2y', 'us_inflation_swap_2y', 
        'trump_odds_dxy', 'trump_odds_spx', 'trump_odds_us_2y', 'trump_odds_inflation_swap']]
y = df['target']  # Replace 'target' with the specific column you're aiming to predict (e.g., SPX returns)

# Step 2: Model Setup with Ridge Regression
ridge = make_pipeline(StandardScaler(), Ridge(alpha=1.0))  # StandardScaler helps with interaction term scaling

# Step 3: Cross-Validation for Evaluation
# Using cross-validation to assess model performance given limited samples
cv_scores = cross_val_score(ridge, X, y, cv=5, scoring='r2')  # Adjust scoring metric as desired

print("Cross-Validation R^2 Scores:", cv_scores)
print("Mean R^2 Score:", np.mean(cv_scores))

# Step 4: Fit the Model (optional, if you want to inspect coefficients)
ridge.fit(X, y)
coefficients = ridge.named_steps['ridge'].coef_
feature_names = X.columns

# Display coefficients
for feature, coef in zip(feature_names, coefficients):
    print(f"{feature}: {coef:.4f}")
